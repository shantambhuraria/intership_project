{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aeea1c4",
   "metadata": {},
   "source": [
    "#### Apriori Algorithm where our number of transcation is the number of days present in the patients data \n",
    "##### Each Transaction will look like [day1,day5,day10,day16] where each value is the day where the compliant time is less than 45 mins for the particular hour like for hour zero the the compliant time was less than 45 mins for day1,day5,day10,day16\n",
    "\n",
    "## OR \n",
    "\n",
    "#### Each Transaction will look like [monday,tuesday,sunday] where each value is the day where the compliant time is less than 40 mins for the particular hour like for hour zero the the compliant time was less than 40 mins for monday,tuesday,sunday\n",
    "\n",
    "\n",
    "##### Indexing based on the date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ac0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries required \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from mpl_toolkits import mplot3d\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d710e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data :\n",
    "df1=pd.read_csv('cpmp_13038.csv')\n",
    "df2=pd.read_csv('13058_hourly_compliance.csv')\n",
    "df3=pd.read_csv('cpmp_13536.csv')\n",
    "\n",
    "df1=df1.sort_values(by=['local_date','hour'],inplace=False)\n",
    "df2=df2.sort_values(by=['local_date','hour'],inplace=False)\n",
    "df3=df3.sort_values(by=['local_date','hour'],inplace=False)\n",
    "\n",
    "df1=df1[['local_date','hour','compliant_min']]\n",
    "df2=df2[['local_date','hour','compliant_min']]\n",
    "df3=df3[['local_date','hour','compliant_min']]\n",
    "\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df3 = df3.reset_index(drop=True)\n",
    "\n",
    "# Convert 'local_date' column to datetime type\n",
    "df1['local_date'] = pd.to_datetime(df1['local_date'])\n",
    "df2['local_date'] = pd.to_datetime(df2['local_date'])\n",
    "\n",
    "df3['local_date'] = pd.to_datetime(df3['local_date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3f021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_date</th>\n",
       "      <th>hour</th>\n",
       "      <th>compliant_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1291 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     local_date  hour  compliant_min\n",
       "0    2022-02-25     0              0\n",
       "1    2022-02-25     1              0\n",
       "2    2022-02-25     2              0\n",
       "3    2022-02-25     3              0\n",
       "4    2022-02-25     4              0\n",
       "...         ...   ...            ...\n",
       "1286 2022-04-29    14              0\n",
       "1287 2022-04-29    15              0\n",
       "1288 2022-04-29    16              0\n",
       "1289 2022-04-29    17              0\n",
       "1290 2022-04-29    18              0\n",
       "\n",
       "[1291 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da87fbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     local_date  hour  compliant_min\n",
      "0    2022-02-25     0            0.0\n",
      "1    2022-02-25     1            0.0\n",
      "2    2022-02-25     2            0.0\n",
      "3    2022-02-25     3            0.0\n",
      "4    2022-02-25     4            0.0\n",
      "...         ...   ...            ...\n",
      "1531 2022-04-29    19            0.0\n",
      "1532 2022-04-29    20            0.0\n",
      "1533 2022-04-29    21            0.0\n",
      "1534 2022-04-29    22            0.0\n",
      "1535 2022-04-29    23            0.0\n",
      "\n",
      "[1536 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1['local_date'] = pd.to_datetime(df1['local_date'])\n",
    "\n",
    "\n",
    "start_date = df1['local_date'].min()\n",
    "end_date = df1['local_date'].max()\n",
    "\n",
    "\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "\n",
    "all_dates_df = pd.DataFrame({'local_date': date_range})\n",
    "\n",
    "\n",
    "all_hours = range(24)\n",
    "\n",
    "\n",
    "all_hours_df = pd.DataFrame({'hour': all_hours})\n",
    "\n",
    "\n",
    "all_dates_hours_df = all_dates_df.assign(key=1).merge(all_hours_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "\n",
    "\n",
    "merged_df = all_dates_hours_df.merge(df1, on=['local_date', 'hour'], how='left')\n",
    "\n",
    "\n",
    "merged_df['compliant_min'] = merged_df['compliant_min'].fillna(0)\n",
    "\n",
    "\n",
    "merged_df = merged_df.sort_values(['local_date', 'hour']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f10bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a45f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac42e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map unique days to day names\n",
    "unique_days1 = df1['local_date'].dt.date.unique()\n",
    "day_names1 = {day: f'day{i+1}' for i, day in enumerate(unique_days1)}\n",
    "\n",
    "# Add a new column with day names\n",
    "df1['day'] = df1['local_date'].dt.date.map(day_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "598ba31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c691b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.sort_values(by=['local_date','hour'],inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c66198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_date</th>\n",
       "      <th>hour</th>\n",
       "      <th>compliant_min</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1536 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     local_date  hour  compliant_min    day\n",
       "0    2022-02-25     0            0.0   day1\n",
       "1    2022-02-25     1            0.0   day1\n",
       "2    2022-02-25     2            0.0   day1\n",
       "3    2022-02-25     3            0.0   day1\n",
       "4    2022-02-25     4            0.0   day1\n",
       "...         ...   ...            ...    ...\n",
       "1531 2022-04-29    19            0.0  day64\n",
       "1532 2022-04-29    20            0.0  day64\n",
       "1533 2022-04-29    21            0.0  day64\n",
       "1534 2022-04-29    22            0.0  day64\n",
       "1535 2022-04-29    23            0.0  day64\n",
       "\n",
       "[1536 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c76159ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def generate_heatmap1(df):\n",
    "    # Create a copy of the dataframe\n",
    "    patient_heat_map = df.copy()\n",
    "\n",
    "    # Convert 'compliant_min' to integer\n",
    "    patient_heat_map['compliant_min'] = patient_heat_map['compliant_min'].astype(int)\n",
    "\n",
    "    # Get unique days in the DataFrame\n",
    "    unique_days = patient_heat_map['day'].unique()\n",
    "    unique_days = sorted(unique_days, key=lambda x: int(x[3:]))  # Sort the days numerically\n",
    "\n",
    "    # Pivot the data\n",
    "    pivot_data = patient_heat_map.pivot('hour', 'day', 'compliant_min')\n",
    "\n",
    "    # Reorder the columns based on the sorted unique days\n",
    "    pivot_data = pivot_data[unique_days]\n",
    "\n",
    "    # Increase the figure size for better visibility\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Creating the heatmap\n",
    "    sns.heatmap(pivot_data, cmap='RdYlGn', vmin=0, vmax=60, cbar=True, linewidths=0.5, linecolor='gray')\n",
    "\n",
    "    # Add lines to separate hours and days\n",
    "    plt.hlines(y=range(0, len(pivot_data.index)), xmin=0, xmax=len(pivot_data.columns), color='gray', linewidths=0.5)\n",
    "    plt.vlines(x=range(0, len(pivot_data.columns)), ymin=0, ymax=len(pivot_data.index), color='gray', linewidths=0.5)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title('Compliant Minutes Heatmap', fontsize=16)\n",
    "    plt.xlabel('Day', fontsize=14)\n",
    "    plt.ylabel('Hour', fontsize=14)\n",
    "\n",
    "    # Increase the font size of the x-axis and y-axis labels\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    # Save the plot to a BytesIO object\n",
    "    plot_bytes = io.BytesIO()\n",
    "    plt.savefig(plot_bytes, format='png', dpi=400)  # Increase the dpi for higher resolution\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Reset the buffer position to the start\n",
    "    plot_bytes.seek(0)\n",
    "\n",
    "    # Return the BytesIO object\n",
    "    return plot_bytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df1[df1['compliant_min'] < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['day_of_week'] = df1['local_date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf0788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cd628d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'day'\n",
    "grouped_by_day = df1.groupby('day')\n",
    "\n",
    "# Filter and keep only the days with more than 5 rows where 'compliant_min' is less than 30\n",
    "filtered_days = grouped_by_day.filter(lambda x: (x['compliant_min'] < 30).sum() > 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "998e014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_date</th>\n",
       "      <th>hour</th>\n",
       "      <th>compliant_min</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     local_date  hour  compliant_min    day\n",
       "0    2022-02-25     0            0.0   day1\n",
       "1    2022-02-25     1            0.0   day1\n",
       "2    2022-02-25     2            0.0   day1\n",
       "3    2022-02-25     3            0.0   day1\n",
       "4    2022-02-25     4            0.0   day1\n",
       "...         ...   ...            ...    ...\n",
       "1531 2022-04-29    19            0.0  day64\n",
       "1532 2022-04-29    20            0.0  day64\n",
       "1533 2022-04-29    21            0.0  day64\n",
       "1534 2022-04-29    22            0.0  day64\n",
       "1535 2022-04-29    23            0.0  day64\n",
       "\n",
       "[624 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ab4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For hour 0: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 1: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 2: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 3: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 4: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 5: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 6: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 7: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 8: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 9: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 10: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 11: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 12: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 13: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 14: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 15: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 16: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 17: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 18: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 19: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 20: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 21: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 22: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 23: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for each hour\n",
    "filtered_data = []\n",
    "for hour in range(24):\n",
    "    hour_data = filtered_days[filtered_days['hour'] == hour]['day'].tolist()\n",
    "    filtered_data.append(tuple(hour_data))\n",
    "\n",
    "# Store the filtered data as a tuple\n",
    "filtered_data_tuple = tuple(filtered_data)\n",
    "\n",
    "# Print the result\n",
    "for hour, data in enumerate(filtered_data_tuple):\n",
    "    print(f\"For hour {hour}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b7f8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For hour 0: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 1: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 2: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 3: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 4: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 5: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 6: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 7: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 8: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 9: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 10: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 11: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 12: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 13: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 14: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 15: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 16: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 17: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 18: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 19: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 20: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 21: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 22: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n",
      "For hour 23: ('day1', 'day6', 'day7', 'day8', 'day9', 'day10', 'day11', 'day12', 'day13', 'day31', 'day32', 'day40', 'day41', 'day42', 'day43', 'day44', 'day45', 'day46', 'day48', 'day50', 'day53', 'day56', 'day57', 'day60', 'day62', 'day64')\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each day across all hours\n",
    "day_counts = Counter([day for hour_data in filtered_data_tuple for day in hour_data])\n",
    "\n",
    "# Get the days that occurred at least 8 times\n",
    "days_to_keep = set(day for day, count in day_counts.items() if count >= 5)\n",
    "\n",
    "# Filter the tuples by removing the days that occurred fewer than 8 times\n",
    "filtered_data_tuple_filtered = tuple([tuple(day for day in hour_data if day in days_to_keep) for hour_data in filtered_data_tuple])\n",
    "\n",
    "# Print the result\n",
    "for hour, data in enumerate(filtered_data_tuple_filtered):\n",
    "    print(f\"For hour {hour}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dbb3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ccb3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the filtered_data_tuple_filtered into a list of transactions\n",
    "transactions = list(filtered_data_tuple_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e13e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "# Apply TransactionEncoder to the list of transactions\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "# Convert the encoded array into a DataFrame\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97991560",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply Apriori algorithm to find frequent itemsets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m frequent_itemsets \u001b[38;5;241m=\u001b[39m \u001b[43mapriori\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_colnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\Public\\Downloads\\anaconda\\lib\\site-packages\\mlxtend\\frequent_patterns\\apriori.py:324\u001b[0m, in \u001b[0;36mapriori\u001b[1;34m(df, min_support, use_colnames, max_len, verbose, low_memory)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(itemset_dict):\n\u001b[0;32m    323\u001b[0m     support \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(support_dict[k])\n\u001b[1;32m--> 324\u001b[0m     itemsets \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;28mfrozenset\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m itemset_dict[k]], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    326\u001b[0m     res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat((support, itemsets), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    327\u001b[0m     all_res\u001b[38;5;241m.\u001b[39mappend(res)\n",
      "File \u001b[1;32mC:\\Users\\Public\\Downloads\\anaconda\\lib\\site-packages\\mlxtend\\frequent_patterns\\apriori.py:324\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(itemset_dict):\n\u001b[0;32m    323\u001b[0m     support \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(support_dict[k])\n\u001b[1;32m--> 324\u001b[0m     itemsets \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;28mfrozenset\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m itemset_dict[k]], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    326\u001b[0m     res \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat((support, itemsets), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    327\u001b[0m     all_res\u001b[38;5;241m.\u001b[39mappend(res)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.75, use_colnames=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2961a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the frequent itemsets by support in descending order\n",
    "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee44e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the itemsets column to frozensets\n",
    "frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(frozenset)\n",
    "\n",
    "# Drop duplicate rows based on the frozensets in the itemsets column\n",
    "frequent_itemsets = frequent_itemsets.drop_duplicates(subset='itemsets')\n",
    "\n",
    "frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(set)\n",
    "\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to get itemsets with support of 0.5\n",
    "filtered_itemsets = frequent_itemsets[frequent_itemsets['support'] > 0.7]\n",
    "\n",
    "filtered_itemsets = filtered_itemsets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306312a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_itemsets.itemsets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out itemsets with a single value\n",
    "frequent_itemsets_filtered = frequent_itemsets[frequent_itemsets['itemsets'].apply(lambda x: len(x) ==1)]\n",
    "\n",
    "# Print the filtered frequent itemsets\n",
    "print(frequent_itemsets_filtered.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95970b0a",
   "metadata": {},
   "source": [
    "## days for which the patient is least compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fecbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for each hour\n",
    "filtered_data = []\n",
    "for hour in range(24):\n",
    "    hour_data = filtered_days[filtered_days['hour'] == hour]['day_of_week'].tolist()\n",
    "    filtered_data.append(tuple(hour_data))\n",
    "\n",
    "# Store the filtered data as a tuple\n",
    "filtered_data_tuple = tuple(filtered_data)\n",
    "\n",
    "# Print the result\n",
    "for hour, data in enumerate(filtered_data_tuple):\n",
    "    print(f\"For hour {hour}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each day across all hours\n",
    "day_counts = Counter([day for hour_data in filtered_data_tuple for day in hour_data])\n",
    "\n",
    "# Get the days that occurred at least 8 times\n",
    "days_to_keep = set(day for day, count in day_counts.items() if count >= 0)\n",
    "\n",
    "# Filter the tuples by removing the days that occurred fewer than 8 times\n",
    "filtered_data_tuple_filtered = tuple([tuple(day for day in hour_data if day in days_to_keep) for hour_data in filtered_data_tuple])\n",
    "\n",
    "# Print the result\n",
    "for hour, data in enumerate(filtered_data_tuple_filtered):\n",
    "    print(f\"For hour {hour}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the filtered_data_tuple_filtered into a list of transactions\n",
    "transactions = list(filtered_data_tuple_filtered)\n",
    "# Initialize TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "# Apply TransactionEncoder to the list of transactions\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "# Convert the encoded array into a DataFrame\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.6, use_colnames=True)\n",
    "\n",
    "# Sort the frequent itemsets by support in descending order\n",
    "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beed0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94134dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with unique support values\n",
    "unique_df = frequent_itemsets.drop_duplicates(subset='itemsets')\n",
    "\n",
    "# Print the new dataframe\n",
    "print(unique_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a22983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3014278",
   "metadata": {},
   "source": [
    "### Patient 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3['local_date'] = pd.to_datetime(df3['local_date'])\n",
    "\n",
    "\n",
    "start_date = df3['local_date'].min()\n",
    "end_date = df3['local_date'].max()\n",
    "\n",
    "\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "\n",
    "all_dates_df = pd.DataFrame({'local_date': date_range})\n",
    "\n",
    "\n",
    "all_hours = range(24)\n",
    "\n",
    "\n",
    "all_hours_df = pd.DataFrame({'hour': all_hours})\n",
    "\n",
    "\n",
    "all_dates_hours_df = all_dates_df.assign(key=1).merge(all_hours_df.assign(key=1), on='key').drop('key', axis=1)\n",
    "\n",
    "\n",
    "merged_df = all_dates_hours_df.merge(df1, on=['local_date', 'hour'], how='left')\n",
    "\n",
    "\n",
    "merged_df['compliant_min'] = merged_df['compliant_min'].fillna(0)\n",
    "\n",
    "\n",
    "merged_df = merged_df.sort_values(['local_date', 'hour']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2bde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa432a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map unique days to day names\n",
    "unique_days1 = df3['local_date'].dt.date.unique()\n",
    "day_names1 = {day: f'day{i+1}' for i, day in enumerate(unique_days1)}\n",
    "\n",
    "# Add a new column with day names\n",
    "df3['day'] = df3['local_date'].dt.date.map(day_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df3.sort_values(by=['local_date','hour'],inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde39501",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_heatmap1(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82599f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= df3[df3['compliant_min'] < 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'day'\n",
    "grouped_by_day = df3.groupby('day')\n",
    "\n",
    "# Filter and keep only the days with more than 5 rows where 'compliant_min' is less than 30\n",
    "filtered_days = grouped_by_day.filter(lambda x: (x['compliant_min'] < 30).sum() > 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d693658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for each hour\n",
    "filtered_data = []\n",
    "for hour in range(24):\n",
    "    hour_data = filtered_days[filtered_days['hour'] == hour]['day'].tolist()\n",
    "    filtered_data.append(tuple(hour_data))\n",
    "\n",
    "# Store the filtered data as a tuple\n",
    "filtered_data_tuple = tuple(filtered_data)\n",
    "\n",
    "# Print the result\n",
    "for hour, data in enumerate(filtered_data_tuple):\n",
    "    print(f\"For hour {hour}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cc66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each day across all hours\n",
    "day_counts = Counter([day for hour_data in filtered_data_tuple for day in hour_data])\n",
    "\n",
    "# Get the days that occurred at least 8 times\n",
    "days_to_keep = set(day for day, count in day_counts.items() if count >= 5)\n",
    "\n",
    "# Filter the tuples by removing the days that occurred fewer than 8 times\n",
    "filtered_data_tuple_filtered = tuple([tuple(day for day in hour_data if day in days_to_keep) for hour_data in filtered_data_tuple])\n",
    "\n",
    "# Print the result\n",
    "for hour, data in enumerate(filtered_data_tuple_filtered):\n",
    "    print(f\"For hour {hour}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4fad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the filtered_data_tuple_filtered into a list of transactions\n",
    "transactions = list(filtered_data_tuple_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "# Apply TransactionEncoder to the list of transactions\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "# Convert the encoded array into a DataFrame\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa428733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.5, use_colnames=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddf80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the frequent itemsets by support in descending order\n",
    "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904928d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb248928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data (replace this with your actual data)\n",
    "data = {\n",
    "    'support': [0.875, 0.666667, 0.583333, 0.541667, 0.541667, 0.541667],\n",
    "    'itemsets': [['day2'], ['day28'], ['day4'], ['day14'], ['day14', 'day2'], ['day28', 'day2']]\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert itemsets to strings\n",
    "df['itemsets'] = df['itemsets'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Sort the DataFrame by support values in descending order\n",
    "df = df.sort_values(by='support', ascending=False)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df['itemsets'], df['support'], color='skyblue')\n",
    "plt.xlabel('Itemsets')\n",
    "plt.ylabel('Support')\n",
    "plt.title('Support Values of Frequent Itemsets')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)  # Set the y-axis limit to show support values from 0 to 1\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a046e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data (replace this with your actual data)\n",
    "data = {\n",
    "    'Support': [1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000, 1.000],\n",
    "    'itemsets': ['{day10}', '{day11}', '{day44}', '{day43}', '{day42}', '{day6}', '{day45}', '{day41}', '{day12}', '{day40}']\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert itemsets to strings\n",
    "df['itemsets'] = df['itemsets'].str.strip('{}')\n",
    "\n",
    "# Sort the DataFrame by support values in descending order\n",
    "df = df.sort_values(by='Support', ascending=False)\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df['itemsets'], df['Support'], color='skyblue')\n",
    "plt.xlabel('Itemsets')\n",
    "plt.ylabel('Support')\n",
    "plt.title('Support Values of Frequent Itemsets')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)  # Set the y-axis limit to show support values from 0 to 1\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ead72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
